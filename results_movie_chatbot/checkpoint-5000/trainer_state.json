{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 7.518153667449951,
      "learning_rate": 4.901e-05,
      "loss": 3.2606,
      "step": 100
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.105506420135498,
      "learning_rate": 4.801e-05,
      "loss": 3.1527,
      "step": 200
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.268128871917725,
      "learning_rate": 4.7010000000000006e-05,
      "loss": 3.095,
      "step": 300
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.900078773498535,
      "learning_rate": 4.601e-05,
      "loss": 3.1039,
      "step": 400
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.5855460166931152,
      "learning_rate": 4.5010000000000004e-05,
      "loss": 3.0705,
      "step": 500
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.7203712463378906,
      "learning_rate": 4.401e-05,
      "loss": 3.1649,
      "step": 600
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.9081907272338867,
      "learning_rate": 4.301e-05,
      "loss": 3.0748,
      "step": 700
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.2779016494750977,
      "learning_rate": 4.201e-05,
      "loss": 3.0502,
      "step": 800
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.6365160942077637,
      "learning_rate": 4.101e-05,
      "loss": 3.0939,
      "step": 900
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.810215711593628,
      "learning_rate": 4.0010000000000005e-05,
      "loss": 3.0803,
      "step": 1000
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.802186965942383,
      "learning_rate": 3.901e-05,
      "loss": 3.0638,
      "step": 1100
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.6498355865478516,
      "learning_rate": 3.8010000000000004e-05,
      "loss": 3.0172,
      "step": 1200
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.735931634902954,
      "learning_rate": 3.701e-05,
      "loss": 3.0859,
      "step": 1300
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.6904380321502686,
      "learning_rate": 3.601e-05,
      "loss": 3.0345,
      "step": 1400
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6503114700317383,
      "learning_rate": 3.5010000000000005e-05,
      "loss": 3.0637,
      "step": 1500
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.7736706733703613,
      "learning_rate": 3.401e-05,
      "loss": 3.0423,
      "step": 1600
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.5351972579956055,
      "learning_rate": 3.3010000000000004e-05,
      "loss": 2.9919,
      "step": 1700
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.652942419052124,
      "learning_rate": 3.201e-05,
      "loss": 3.0726,
      "step": 1800
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.796025037765503,
      "learning_rate": 3.101e-05,
      "loss": 3.0481,
      "step": 1900
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.0138156414031982,
      "learning_rate": 3.001e-05,
      "loss": 3.0683,
      "step": 2000
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.8035943508148193,
      "learning_rate": 2.9010000000000005e-05,
      "loss": 3.0178,
      "step": 2100
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.722419023513794,
      "learning_rate": 2.8010000000000005e-05,
      "loss": 3.0521,
      "step": 2200
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.7366950511932373,
      "learning_rate": 2.701e-05,
      "loss": 3.0939,
      "step": 2300
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.5008952617645264,
      "learning_rate": 2.601e-05,
      "loss": 3.0596,
      "step": 2400
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.907132148742676,
      "learning_rate": 2.501e-05,
      "loss": 3.0366,
      "step": 2500
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.0577239990234375,
      "learning_rate": 2.4010000000000002e-05,
      "loss": 3.013,
      "step": 2600
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.817767381668091,
      "learning_rate": 2.301e-05,
      "loss": 3.0151,
      "step": 2700
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.0916919708251953,
      "learning_rate": 2.201e-05,
      "loss": 3.0106,
      "step": 2800
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.9859251976013184,
      "learning_rate": 2.101e-05,
      "loss": 3.0046,
      "step": 2900
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.9113330841064453,
      "learning_rate": 2.001e-05,
      "loss": 3.0843,
      "step": 3000
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.874192237854004,
      "learning_rate": 1.901e-05,
      "loss": 3.0365,
      "step": 3100
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.0769755840301514,
      "learning_rate": 1.8010000000000002e-05,
      "loss": 3.0136,
      "step": 3200
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.7034826278686523,
      "learning_rate": 1.701e-05,
      "loss": 3.0521,
      "step": 3300
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.974255323410034,
      "learning_rate": 1.601e-05,
      "loss": 3.0234,
      "step": 3400
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.0157458782196045,
      "learning_rate": 1.5010000000000002e-05,
      "loss": 3.0085,
      "step": 3500
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.9779298305511475,
      "learning_rate": 1.4010000000000001e-05,
      "loss": 3.0558,
      "step": 3600
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.8368818759918213,
      "learning_rate": 1.301e-05,
      "loss": 3.0179,
      "step": 3700
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.7382586002349854,
      "learning_rate": 1.201e-05,
      "loss": 3.0378,
      "step": 3800
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.1622390747070312,
      "learning_rate": 1.1010000000000001e-05,
      "loss": 3.0219,
      "step": 3900
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.2609848976135254,
      "learning_rate": 1.001e-05,
      "loss": 2.9741,
      "step": 4000
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.0654993057250977,
      "learning_rate": 9.01e-06,
      "loss": 3.0179,
      "step": 4100
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.7985036373138428,
      "learning_rate": 8.010000000000001e-06,
      "loss": 3.0225,
      "step": 4200
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.328648090362549,
      "learning_rate": 7.01e-06,
      "loss": 3.0146,
      "step": 4300
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.572829484939575,
      "learning_rate": 6.01e-06,
      "loss": 2.9998,
      "step": 4400
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.201174736022949,
      "learning_rate": 5.01e-06,
      "loss": 2.9674,
      "step": 4500
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.269361734390259,
      "learning_rate": 4.01e-06,
      "loss": 2.9922,
      "step": 4600
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.0279273986816406,
      "learning_rate": 3.01e-06,
      "loss": 2.9797,
      "step": 4700
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.971282482147217,
      "learning_rate": 2.0100000000000002e-06,
      "loss": 3.0077,
      "step": 4800
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.95119571685791,
      "learning_rate": 1.01e-06,
      "loss": 2.9869,
      "step": 4900
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.6994197368621826,
      "learning_rate": 1e-08,
      "loss": 3.0372,
      "step": 5000
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 731238956531712.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
